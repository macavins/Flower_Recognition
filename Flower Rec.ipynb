{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0463759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 11:27:30.430280: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-14 11:27:31.369939: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9af57ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4262 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2,\n",
    "                horizontal_flip = True)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "                'training_set', target_size = (64,64), batch_size=32, class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85ce1935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 129 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "                rescale=1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "                'test_set', target_size = (64,64), batch_size=32, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7022ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 11:27:32.976337: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2f590b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size = 3, activation='relu', input_shape=[64, 64, 3])) # 1st layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48cb2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) # 1st layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee15549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size = 3, activation='relu')) \n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2)) # 2nd layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a29f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dropout(0.5)) # add layer for better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e88f0a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d52bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69a6c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=5, activation='softmax')) # 5 categories, softmax more than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a0aab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e1308e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 11:27:36.008600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - ETA: 0s - loss: 1.4027 - accuracy: 0.4237"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 11:28:02.549023: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 27s 196ms/step - loss: 1.4027 - accuracy: 0.4237 - val_loss: 0.9677 - val_accuracy: 0.5891\n",
      "Epoch 2/30\n",
      "134/134 [==============================] - 26s 193ms/step - loss: 1.0767 - accuracy: 0.5695 - val_loss: 0.9398 - val_accuracy: 0.6124\n",
      "Epoch 3/30\n",
      "134/134 [==============================] - 26s 193ms/step - loss: 0.9981 - accuracy: 0.6150 - val_loss: 0.8254 - val_accuracy: 0.7054\n",
      "Epoch 4/30\n",
      "134/134 [==============================] - 32s 237ms/step - loss: 0.9129 - accuracy: 0.6452 - val_loss: 1.1369 - val_accuracy: 0.6202\n",
      "Epoch 5/30\n",
      "134/134 [==============================] - 31s 228ms/step - loss: 0.8655 - accuracy: 0.6666 - val_loss: 0.7106 - val_accuracy: 0.7442\n",
      "Epoch 6/30\n",
      "134/134 [==============================] - 27s 198ms/step - loss: 0.8106 - accuracy: 0.6886 - val_loss: 0.7725 - val_accuracy: 0.6899\n",
      "Epoch 7/30\n",
      "134/134 [==============================] - 27s 201ms/step - loss: 0.7837 - accuracy: 0.6997 - val_loss: 0.7105 - val_accuracy: 0.7364\n",
      "Epoch 8/30\n",
      "134/134 [==============================] - 27s 199ms/step - loss: 0.7482 - accuracy: 0.7154 - val_loss: 0.7658 - val_accuracy: 0.7054\n",
      "Epoch 9/30\n",
      "134/134 [==============================] - 27s 202ms/step - loss: 0.7116 - accuracy: 0.7302 - val_loss: 0.8153 - val_accuracy: 0.7132\n",
      "Epoch 10/30\n",
      "134/134 [==============================] - 26s 196ms/step - loss: 0.6870 - accuracy: 0.7407 - val_loss: 0.6531 - val_accuracy: 0.7519\n",
      "Epoch 11/30\n",
      "134/134 [==============================] - 27s 197ms/step - loss: 0.6572 - accuracy: 0.7532 - val_loss: 0.6569 - val_accuracy: 0.7209\n",
      "Epoch 12/30\n",
      "134/134 [==============================] - 27s 198ms/step - loss: 0.6427 - accuracy: 0.7555 - val_loss: 0.5903 - val_accuracy: 0.7442\n",
      "Epoch 13/30\n",
      "134/134 [==============================] - 27s 199ms/step - loss: 0.6243 - accuracy: 0.7694 - val_loss: 0.7171 - val_accuracy: 0.7442\n",
      "Epoch 14/30\n",
      "134/134 [==============================] - 27s 199ms/step - loss: 0.6159 - accuracy: 0.7710 - val_loss: 0.6254 - val_accuracy: 0.7597\n",
      "Epoch 15/30\n",
      "134/134 [==============================] - 26s 196ms/step - loss: 0.5668 - accuracy: 0.7884 - val_loss: 0.6618 - val_accuracy: 0.7287\n",
      "Epoch 16/30\n",
      "134/134 [==============================] - 26s 195ms/step - loss: 0.5688 - accuracy: 0.7931 - val_loss: 0.5914 - val_accuracy: 0.7597\n",
      "Epoch 17/30\n",
      "134/134 [==============================] - 26s 196ms/step - loss: 0.5460 - accuracy: 0.7921 - val_loss: 0.5835 - val_accuracy: 0.7829\n",
      "Epoch 18/30\n",
      "134/134 [==============================] - 26s 196ms/step - loss: 0.5218 - accuracy: 0.8043 - val_loss: 0.7105 - val_accuracy: 0.7442\n",
      "Epoch 19/30\n",
      "134/134 [==============================] - 26s 197ms/step - loss: 0.4976 - accuracy: 0.8151 - val_loss: 0.5783 - val_accuracy: 0.7674\n",
      "Epoch 20/30\n",
      "134/134 [==============================] - 27s 202ms/step - loss: 0.4853 - accuracy: 0.8217 - val_loss: 0.7062 - val_accuracy: 0.7907\n",
      "Epoch 21/30\n",
      "134/134 [==============================] - 27s 197ms/step - loss: 0.4785 - accuracy: 0.8240 - val_loss: 0.6652 - val_accuracy: 0.7674\n",
      "Epoch 22/30\n",
      "134/134 [==============================] - 27s 198ms/step - loss: 0.4498 - accuracy: 0.8322 - val_loss: 0.7387 - val_accuracy: 0.7752\n",
      "Epoch 23/30\n",
      "134/134 [==============================] - 27s 198ms/step - loss: 0.4336 - accuracy: 0.8386 - val_loss: 0.5768 - val_accuracy: 0.7984\n",
      "Epoch 24/30\n",
      "134/134 [==============================] - 27s 198ms/step - loss: 0.4339 - accuracy: 0.8397 - val_loss: 0.6939 - val_accuracy: 0.7984\n",
      "Epoch 25/30\n",
      "134/134 [==============================] - 26s 195ms/step - loss: 0.4177 - accuracy: 0.8426 - val_loss: 0.5775 - val_accuracy: 0.7984\n",
      "Epoch 26/30\n",
      "134/134 [==============================] - 26s 194ms/step - loss: 0.3838 - accuracy: 0.8590 - val_loss: 0.5975 - val_accuracy: 0.7752\n",
      "Epoch 27/30\n",
      "134/134 [==============================] - 32s 240ms/step - loss: 0.4015 - accuracy: 0.8552 - val_loss: 0.4972 - val_accuracy: 0.8062\n",
      "Epoch 28/30\n",
      "134/134 [==============================] - 26s 194ms/step - loss: 0.3715 - accuracy: 0.8674 - val_loss: 0.5436 - val_accuracy: 0.7984\n",
      "Epoch 29/30\n",
      "134/134 [==============================] - 32s 238ms/step - loss: 0.3676 - accuracy: 0.8660 - val_loss: 0.5464 - val_accuracy: 0.8372\n",
      "Epoch 30/30\n",
      "134/134 [==============================] - 26s 193ms/step - loss: 0.3616 - accuracy: 0.8656 - val_loss: 0.5579 - val_accuracy: 0.8295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8522e325c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set, validation_data=test_set, epochs = 30) # epochs is cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b3fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "test_image = image.load_img('Prediction/sunf.jpg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "result = cnn.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3edc48d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daisy': 0, 'dandelion': 1, 'rose': 2, 'sunflower': 3, 'tulip': 4}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f1db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4783013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sunflower\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    print('Daisy')\n",
    "elif result[0][1]==1:\n",
    "    print('Dandelion')\n",
    "elif result[0][2]==1:\n",
    "    print('rose')\n",
    "elif result[0][3]==1:\n",
    "    print('Sunflower')\n",
    "elif result[0][4]==1:\n",
    "    print('tulip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20c290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
